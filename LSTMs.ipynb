{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install torch datasets scikit-learn matplotlib\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqhRxSO784S1",
        "outputId": "113b02dc-2a33-4c84-c7a1-b6581cc995f3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.15.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.10.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec (from torch)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.9)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWnSDyuQ_EWl",
        "outputId": "8aff722c-3450-4488-edd5-8f003b83a9e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x798328d6d750>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import nltk\n",
        "import pandas as pd\n",
        "\n",
        "torch.manual_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NFy16uwzo8a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627,
          "referenced_widgets": [
            "ab9123f42c08423aa16d9906fe694a1c",
            "8110cac858c9446288db05bddccd4c78",
            "97784268e3d04e07bb83bed9e658d882",
            "2a81df29195b410583953112666ab28f",
            "d0dbf2fcfb454731ab0fa1683a5b792c",
            "0a928ea2b8e740a8805bbc2134169c54",
            "84ef4704ffc24560b942ba727b836eff",
            "d9a50fa2a35349e2b70ddf3799317972",
            "f8e564127968468898af3d13238db249",
            "939626febc744970b9d14e1b9df0903e",
            "d055436f79d04720bd03c0d53d50246a",
            "3de1ce76fde44c61b2b16a0d1ddbb7c5",
            "7fbeb1ed7a9e4a22bbe26255339b1473",
            "8759087d21a94d6496bdbbff733819a4",
            "0bf78e0ad0be466885c93870a052df77",
            "744b99a8fe0c496d862a851e5826bf95",
            "cfd25d670baa4befbe6f83b5c512d7a7",
            "47a7c33970ab496ca5d76e9851249cf4",
            "347c82fe29c84173a113caf760989432",
            "3a1ee67a1223412984d20073b075f124",
            "01d59d717f404641a0662b8806d7fff3",
            "6fc67b7b97364f77af571f1ce5cec01e",
            "ca1fdf989c5c45f98b06ff2ba512c2ac",
            "ed1644d1dd044cf582f5611cac17aa48",
            "6226f5db394742d48a617c44bcf939a9",
            "8178fe7f673041d7a343a271b4560a31",
            "6579af1796624f18ba21f7d09669b78b",
            "a69091abe2ed42f084380bdf45433efe",
            "ec67655aecca445ab72d649d17521145",
            "023a957f7f6345b5a63e803581dc2739",
            "f691fb675bde4705b7a99f52af33f502",
            "d3fb0ea703444c7684c47c25ee3be5a2",
            "637f8e869ed64106af6bfaeb8f93d8c7"
          ]
        },
        "outputId": "35c35cf0-c185-4a2a-f32d-72c0537c8bc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/348 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab9123f42c08423aa16d9906fe694a1c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentences.csv:   0%|          | 0.00/6.34M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3de1ce76fde44c61b2b16a0d1ddbb7c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating sentences split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca1fdf989c5c45f98b06ff2ba512c2ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              darija  \\\n",
              "0               homa mkhbbyin chi haja, ana mti99en!   \n",
              "1                 bayna homa tay7awlo ib9aw mbrrdin.   \n",
              "2             loTilat mabaynach fihom mori7in bzzaf.   \n",
              "3                 ghaliban ghayjrriw 3lih mn lkhdma!   \n",
              "4                                Tab3an rah mkta2eb!   \n",
              "...                                              ...   \n",
              "87780          galou bli hadchi likayw9a3 rah khatir   \n",
              "87781                   kolchi na3as ana 3asa 3lihom   \n",
              "87782            ydi t9ila 3liya kanhas brasi m3asba   \n",
              "87783  hadchi liw9ah mouakharn makhlach 3andi tarkiz   \n",
              "87784         achnou liw9a3 lik bach tgoli had lhdra   \n",
              "\n",
              "                                                     eng  \\\n",
              "0                    They're hiding something, I'm sure!   \n",
              "1        It's obvious they're trying to keep their cool.   \n",
              "2                the hotels don't seem very comfortable.   \n",
              "3      he is probably about to be laid off by head of...   \n",
              "4                             of course he's depressive!   \n",
              "...                                                  ...   \n",
              "87780                                               None   \n",
              "87781                                               None   \n",
              "87782                                               None   \n",
              "87783                                               None   \n",
              "87784                                               None   \n",
              "\n",
              "                                      darija_ar  \n",
              "0             هوما مخبّيين شي حاجة, أنا متيقّن!  \n",
              "1            باينا هوما تايحاولو إبقاو مبرّدين.  \n",
              "2         لوطيلات مابايناش فيهوم موريحين بزّاف.  \n",
              "3               غاليبان غايجرّيو عليه من لخدما!  \n",
              "4                            طابعان راه مكتاءب!  \n",
              "...                                         ...  \n",
              "87780        ڭالو بلي هادشي ليكايوقاع راه خاتير  \n",
              "87781               كولشي ناعاس أنا عاسا عليهوم  \n",
              "87782       يدي تقيلا علييا كانهاس براسي معاسبا  \n",
              "87783  هادشي ليوقاه مواخارن ماخلاش عاندي تاركيز  \n",
              "87784       أشنو ليوقاع ليك باش تڭولي هاد لهدرا  \n",
              "\n",
              "[87785 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a43d6734-3f72-4009-b569-222bef02745e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>darija</th>\n",
              "      <th>eng</th>\n",
              "      <th>darija_ar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>homa mkhbbyin chi haja, ana mti99en!</td>\n",
              "      <td>They're hiding something, I'm sure!</td>\n",
              "      <td>هوما مخبّيين شي حاجة, أنا متيقّن!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bayna homa tay7awlo ib9aw mbrrdin.</td>\n",
              "      <td>It's obvious they're trying to keep their cool.</td>\n",
              "      <td>باينا هوما تايحاولو إبقاو مبرّدين.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>loTilat mabaynach fihom mori7in bzzaf.</td>\n",
              "      <td>the hotels don't seem very comfortable.</td>\n",
              "      <td>لوطيلات مابايناش فيهوم موريحين بزّاف.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ghaliban ghayjrriw 3lih mn lkhdma!</td>\n",
              "      <td>he is probably about to be laid off by head of...</td>\n",
              "      <td>غاليبان غايجرّيو عليه من لخدما!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tab3an rah mkta2eb!</td>\n",
              "      <td>of course he's depressive!</td>\n",
              "      <td>طابعان راه مكتاءب!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87780</th>\n",
              "      <td>galou bli hadchi likayw9a3 rah khatir</td>\n",
              "      <td>None</td>\n",
              "      <td>ڭالو بلي هادشي ليكايوقاع راه خاتير</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87781</th>\n",
              "      <td>kolchi na3as ana 3asa 3lihom</td>\n",
              "      <td>None</td>\n",
              "      <td>كولشي ناعاس أنا عاسا عليهوم</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87782</th>\n",
              "      <td>ydi t9ila 3liya kanhas brasi m3asba</td>\n",
              "      <td>None</td>\n",
              "      <td>يدي تقيلا علييا كانهاس براسي معاسبا</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87783</th>\n",
              "      <td>hadchi liw9ah mouakharn makhlach 3andi tarkiz</td>\n",
              "      <td>None</td>\n",
              "      <td>هادشي ليوقاه مواخارن ماخلاش عاندي تاركيز</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87784</th>\n",
              "      <td>achnou liw9a3 lik bach tgoli had lhdra</td>\n",
              "      <td>None</td>\n",
              "      <td>أشنو ليوقاع ليك باش تڭولي هاد لهدرا</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>87785 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a43d6734-3f72-4009-b569-222bef02745e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a43d6734-3f72-4009-b569-222bef02745e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a43d6734-3f72-4009-b569-222bef02745e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c336c994-0666-45ad-a992-304c05027b25\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c336c994-0666-45ad-a992-304c05027b25')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c336c994-0666-45ad-a992-304c05027b25 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f8e49b75-6c48-438c-9db6-8cf68282e4bc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dataset')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f8e49b75-6c48-438c-9db6-8cf68282e4bc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('dataset');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 87785,\n  \"fields\": [\n    {\n      \"column\": \"darija\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 87457,\n        \"samples\": [\n          \"whiya 3wdat l3am\",\n          \"lhadra machi hia li ghadi twassik\",\n          \"mab9itch baghi ndewwi lbit kter men l9yass\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eng\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11544,\n        \"samples\": [\n          \"We need to make a plan\",\n          \"Yes, a chocolate cake, and another apple I think.\",\n          \"He might get even sicker!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"darija_ar\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 86846,\n        \"samples\": [\n          \"\\u0645\\u0627\\u0628\\u063a\\u064a\\u062a\\u064a\\u0634 \\u062a \\u062e\\u0631\\u0642 \\u0641\\u0647\\u0627\\u062f\\u0634\\u064a \\u062d\\u064a\\u062a \\u0645\\u0648\\u0647\\u064a\\u0645 \\u0641\\u062e\\u062f\\u0645\\u062a\\u0643\",\n          \"\\u0625\\u0645\\u062a\\u0627 \\u063a\\u0627\\u062f\\u064a \\u062a \\u0645\\u0633\\u0651\\u0646\\u064a \\u063a\\u064a\\u0631 \\u0625\\u0644\\u0627 \\u062d\\u062a\\u0627\\u0642\\u0631\\u062a\\u064a\\u0646\\u064a\",\n          \"\\u0631\\u0627\\u0643\\u064a \\u0645\\u0639\\u0631\\u0648\\u062f\\u0627 \\u0644\\u0639\\u0627\\u0631\\u0633\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from datasets import load_dataset_builder\n",
        "\n",
        "dataset = load_dataset(\"imomayiz/darija-english\", 'sentences')\n",
        "\n",
        "dataset.set_format(type='pandas', output_all_columns=True)\n",
        "dataset = dataset['sentences'][:]\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = dataset.dropna()\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "yMSuCIsqIOnv",
        "outputId": "cf30cb19-1ba5-4e0e-c7ef-4da2b63c3913"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       darija  \\\n",
              "0        homa mkhbbyin chi haja, ana mti99en!   \n",
              "1          bayna homa tay7awlo ib9aw mbrrdin.   \n",
              "2      loTilat mabaynach fihom mori7in bzzaf.   \n",
              "3          ghaliban ghayjrriw 3lih mn lkhdma!   \n",
              "4                         Tab3an rah mkta2eb!   \n",
              "...                                       ...   \n",
              "12742         ra deja chet imta 5aykoun lfilm   \n",
              "12743            nhar l7ed 5aydar flil m3etel   \n",
              "12744        ana kangoul nmchiw nt3echaw 9bel   \n",
              "12745                               blan nadi   \n",
              "12746               film ou 3cha a7ssen combo   \n",
              "\n",
              "                                                     eng  \\\n",
              "0                    They're hiding something, I'm sure!   \n",
              "1        It's obvious they're trying to keep their cool.   \n",
              "2                the hotels don't seem very comfortable.   \n",
              "3      he is probably about to be laid off by head of...   \n",
              "4                             of course he's depressive!   \n",
              "...                                                  ...   \n",
              "12742                 i've already checked the showtimes   \n",
              "12743         there's a late night screening on saturday   \n",
              "12744  i'm thinking we could grab some dinner before ...   \n",
              "12745                                that's a great plan   \n",
              "12746             dinner and a movie, the ultimate combo   \n",
              "\n",
              "                                   darija_ar  \n",
              "0          هوما مخبّيين شي حاجة, أنا متيقّن!  \n",
              "1         باينا هوما تايحاولو إبقاو مبرّدين.  \n",
              "2      لوطيلات مابايناش فيهوم موريحين بزّاف.  \n",
              "3            غاليبان غايجرّيو عليه من لخدما!  \n",
              "4                         طابعان راه مكتاءب!  \n",
              "...                                      ...  \n",
              "12742            را دجا شت إمتا خايكون لفيلم  \n",
              "12743              نهار لحد خايدار فليل معتل  \n",
              "12744            أنا كانڭول نمشيو نتعشاو قبل  \n",
              "12745                              بلان نادي  \n",
              "12746                 فيلم و عشا أحسّن كومبو  \n",
              "\n",
              "[12743 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a19445ae-784f-4985-93d2-adf44c5c3e96\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>darija</th>\n",
              "      <th>eng</th>\n",
              "      <th>darija_ar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>homa mkhbbyin chi haja, ana mti99en!</td>\n",
              "      <td>They're hiding something, I'm sure!</td>\n",
              "      <td>هوما مخبّيين شي حاجة, أنا متيقّن!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bayna homa tay7awlo ib9aw mbrrdin.</td>\n",
              "      <td>It's obvious they're trying to keep their cool.</td>\n",
              "      <td>باينا هوما تايحاولو إبقاو مبرّدين.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>loTilat mabaynach fihom mori7in bzzaf.</td>\n",
              "      <td>the hotels don't seem very comfortable.</td>\n",
              "      <td>لوطيلات مابايناش فيهوم موريحين بزّاف.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ghaliban ghayjrriw 3lih mn lkhdma!</td>\n",
              "      <td>he is probably about to be laid off by head of...</td>\n",
              "      <td>غاليبان غايجرّيو عليه من لخدما!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tab3an rah mkta2eb!</td>\n",
              "      <td>of course he's depressive!</td>\n",
              "      <td>طابعان راه مكتاءب!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12742</th>\n",
              "      <td>ra deja chet imta 5aykoun lfilm</td>\n",
              "      <td>i've already checked the showtimes</td>\n",
              "      <td>را دجا شت إمتا خايكون لفيلم</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12743</th>\n",
              "      <td>nhar l7ed 5aydar flil m3etel</td>\n",
              "      <td>there's a late night screening on saturday</td>\n",
              "      <td>نهار لحد خايدار فليل معتل</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12744</th>\n",
              "      <td>ana kangoul nmchiw nt3echaw 9bel</td>\n",
              "      <td>i'm thinking we could grab some dinner before ...</td>\n",
              "      <td>أنا كانڭول نمشيو نتعشاو قبل</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12745</th>\n",
              "      <td>blan nadi</td>\n",
              "      <td>that's a great plan</td>\n",
              "      <td>بلان نادي</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12746</th>\n",
              "      <td>film ou 3cha a7ssen combo</td>\n",
              "      <td>dinner and a movie, the ultimate combo</td>\n",
              "      <td>فيلم و عشا أحسّن كومبو</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12743 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a19445ae-784f-4985-93d2-adf44c5c3e96')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a19445ae-784f-4985-93d2-adf44c5c3e96 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a19445ae-784f-4985-93d2-adf44c5c3e96');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6f795027-d58c-44fa-92fa-8f6ed4e954f3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6f795027-d58c-44fa-92fa-8f6ed4e954f3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6f795027-d58c-44fa-92fa-8f6ed4e954f3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d2b824bd-95e8-4127-b84e-e9adff6f2ad2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d2b824bd-95e8-4127-b84e-e9adff6f2ad2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 12743,\n  \"fields\": [\n    {\n      \"column\": \"darija\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12461,\n        \"samples\": [\n          \"mo9rach\",\n          \"ch7al mn 5watat 3ndek?\",\n          \"kan7as bchwiya dyal jo3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eng\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11544,\n        \"samples\": [\n          \"We need to make a plan\",\n          \"Yes, a chocolate cake, and another apple I think.\",\n          \"He might get even sicker!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"darija_ar\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12169,\n        \"samples\": [\n          \"\\u0644\\u0627\\u0648\\u0639\\u0644\\u0645\",\n          \"\\u0635\\u0639\\u064a\\u0628 \\u062a\\u0627\\u064a\\u0627\\u0628 \\u0644\\u0628\\u0627\\u0637\\u0651\",\n          \"\\u0623\\u0634 \\u0647\\u0627\\u062f \\u0633\\u062f\\u0627\\u0639 \\u0623\\u064f \\u0625\\u0631\\u062a\\u064a\\u0639\\u0627\\u0634 \\u0644\\u063a\\u0627\\u0631\\u064a\\u0628?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "def build_vocabulary(texts, max_size=10000):\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "    all_tokens = []\n",
        "    for text in texts:\n",
        "        tokens = [token.text.lower() for token in nlp(text)]\n",
        "        all_tokens.extend(tokens)\n",
        "\n",
        "    # Create vocabulary\n",
        "    token_counts = {}\n",
        "    for token in all_tokens:\n",
        "        token_counts[token] = token_counts.get(token, 0) + 1\n",
        "\n",
        "    # Sort tokens by frequency\n",
        "    sorted_tokens = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Create vocabulary dictionary\n",
        "    vocab = {\n",
        "        '<pad>': 0,\n",
        "        '<unk>': 1,\n",
        "        '<sos>': 2,\n",
        "        '<eos>': 3\n",
        "    }\n",
        "\n",
        "    # Add most frequent tokens\n",
        "    for token, _ in sorted_tokens[:]:\n",
        "        if token not in vocab:\n",
        "            vocab[token] = len(vocab)\n",
        "\n",
        "    return vocab\n",
        "\n"
      ],
      "metadata": {
        "id": "ut4lejlO9W33"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import unicodedata\n",
        "# from nltk.translate.bleu_score import sentence_bleu\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import unicodedata\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        progress_bar = tqdm(dataloader, desc=\"Evaluating\", unit=\"batch\")\n",
        "        for source, target in progress_bar:\n",
        "            source = source.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            output = model(source, target[:, :-1])\n",
        "\n",
        "            loss = criterion(\n",
        "                output.contiguous().view(-1, output.size(-1)),\n",
        "                target[:, 1:].contiguous().view(-1)\n",
        "            )\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            progress_bar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def plot_training_history(train_losses, val_losses):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_history.png')\n",
        "    plt.close()\n",
        "\n",
        "def train_translation_model(\n",
        "    lstm_type='vanilla',\n",
        "    hidden_size=256,\n",
        "    learning_rate=0.01,\n",
        "    batch_size=64,\n",
        "    epochs=50\n",
        "):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    (train_english, train_darija), (test_english, test_darija) = prepare_dataset()\n",
        "\n",
        "    source_vocab = build_vocabulary(train_english)\n",
        "    target_vocab = build_vocabulary(train_darija)\n",
        "\n",
        "    train_dataset = LanguageDataset(\n",
        "        train_english,\n",
        "        train_darija,\n",
        "        source_vocab,\n",
        "        target_vocab\n",
        "    )\n",
        "    test_dataset = LanguageDataset(\n",
        "        test_english,\n",
        "        test_darija,\n",
        "        source_vocab,\n",
        "        target_vocab\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_fn\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        collate_fn=collate_fn\n",
        "    )\n",
        "\n",
        "    translator = DarijaTranslator(\n",
        "        source_vocab_size=len(source_vocab),\n",
        "        target_vocab_size=len(target_vocab),\n",
        "        hidden_size=hidden_size,\n",
        "        lstm_type=lstm_type\n",
        "    ).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "    optimizer = optim.Adam(translator.parameters(), lr=learning_rate)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    os.makedirs('results', exist_ok=True)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        train_loss = train_epoch(translator, train_loader, criterion, optimizer, device)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        val_loss = evaluate(translator, test_loader, criterion, device)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        print(f\"Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': translator.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'train_loss': train_loss,\n",
        "            'val_loss': val_loss\n",
        "        }, f'results/translation_model_{lstm_type}_epoch_{epoch+1}.pth')\n",
        "\n",
        "    plot_training_history(train_losses, val_losses)\n",
        "\n",
        "    return translator, train_losses, val_losses\n",
        "\n",
        "def compare_lstm_variants():\n",
        "    lstm_types = ['vanilla', 'peephole', 'working_memory']\n",
        "    results = {}\n",
        "\n",
        "    for lstm_type in lstm_types:\n",
        "        print(f\"\\n--- Training {lstm_type.upper()} LSTM ---\")\n",
        "        model, train_losses, val_losses = train_translation_model(\n",
        "            lstm_type=lstm_type,\n",
        "            hidden_size=256,\n",
        "            learning_rate=0.001,\n",
        "            batch_size=64,\n",
        "            epochs=20\n",
        "        )\n",
        "\n",
        "        results[lstm_type] = {\n",
        "            'model': model,\n",
        "            'train_losses': train_losses,\n",
        "            'val_losses': val_losses\n",
        "        }\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "M7TpeuNuZw_H"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class LanguageDataset(Dataset):\n",
        "    def __init__(self, source_texts, target_texts, source_vocab, target_vocab):\n",
        "        self.source_texts = source_texts\n",
        "        self.target_texts = target_texts\n",
        "        self.source_vocab = source_vocab\n",
        "        self.target_vocab = target_vocab\n",
        "\n",
        "\n",
        "        self.nlp = spacy.load('en_core_web_sm')\n",
        "        # Tokenizers\n",
        "        self.source_tokenizer = lambda x: [token.text.lower() for token in self.nlp(x)]\n",
        "        self.target_tokenizer = lambda x: x.lower().split()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.source_texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Tokenize and convert to indices\n",
        "        source_tokens = [self.source_vocab['<sos>']] + \\\n",
        "                        [self.source_vocab.get(token, self.source_vocab['<unk>']) for token in self.source_tokenizer(self.source_texts[idx])] + \\\n",
        "                        [self.source_vocab['<eos>']]\n",
        "\n",
        "        # For target tokens, use get() method with <unk> as default\n",
        "        target_tokens = [self.target_vocab['<sos>']] + \\\n",
        "                        [self.target_vocab.get(token, self.target_vocab['<unk>']) for token in self.target_tokenizer(self.target_texts[idx])] + \\\n",
        "                        [self.target_vocab['<eos>']]\n",
        "\n",
        "        return (torch.tensor(source_tokens), torch.tensor(target_tokens))\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # Pad sequences\n",
        "    source_sequences = [item[0] for item in batch]\n",
        "    target_sequences = [item[1] for item in batch]\n",
        "\n",
        "    source_padded = pad_sequence(source_sequences, batch_first=True, padding_value=0)\n",
        "    target_padded = pad_sequence(target_sequences, batch_first=True, padding_value=0)\n",
        "\n",
        "    return source_padded, target_padded\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Unicode normalization and lowercasing\n",
        "    text = unicodedata.normalize('NFKD', text.lower())\n",
        "    return text\n",
        "\n",
        "class LSTMBase(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "    def _init_hidden(self, batch_size, device):\n",
        "        return (torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device),\n",
        "                torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device))\n",
        "\n",
        "class VanillaLSTM(LSTMBase):\n",
        "    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.1):\n",
        "        super().__init__(input_size, hidden_size, num_layers, dropout)\n",
        "\n",
        "        self.Wxi = nn.Linear(input_size, hidden_size)\n",
        "        self.Whi = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "        self.Wxf = nn.Linear(input_size, hidden_size)\n",
        "        self.Whf = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "        self.Wxo = nn.Linear(input_size, hidden_size)\n",
        "        self.Who = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "        self.Wxg = nn.Linear(input_size, hidden_size)\n",
        "        self.Whg = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "        device = x.device\n",
        "\n",
        "        if hidden is None:\n",
        "            h, c = self._init_hidden(batch_size, device)\n",
        "        else:\n",
        "            h, c = hidden\n",
        "\n",
        "        outputs = []\n",
        "        for t in range(seq_len):\n",
        "            xt = x[:, t, :]\n",
        "\n",
        "            it = torch.sigmoid(self.Wxi(xt) + self.Whi(h[-1]))\n",
        "\n",
        "            ft = torch.sigmoid(self.Wxf(xt) + self.Whf(h[-1]))\n",
        "\n",
        "            ot = torch.sigmoid(self.Wxo(xt) + self.Who(h[-1]))\n",
        "\n",
        "            gt = torch.tanh(self.Wxg(xt) + self.Whg(h[-1]))\n",
        "\n",
        "            c = ft * c + it * gt\n",
        "\n",
        "            h = ot * torch.tanh(c)\n",
        "\n",
        "            outputs.append(h)\n",
        "\n",
        "        return torch.stack(outputs, dim=1), (h, c)\n",
        "\n",
        "class PeepholeLSTM(LSTMBase):\n",
        "    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.1):\n",
        "        super().__init__(input_size, hidden_size, num_layers, dropout)\n",
        "\n",
        "        self.Wxi = nn.Linear(input_size, hidden_size)\n",
        "        self.Whi = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Wci = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "        self.Wxf = nn.Linear(input_size, hidden_size)\n",
        "        self.Whf = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Wcf = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "        self.Wxo = nn.Linear(input_size, hidden_size)\n",
        "        self.Who = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Wco = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "        self.Wxg = nn.Linear(input_size, hidden_size)\n",
        "        self.Whg = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "        device = x.device\n",
        "\n",
        "        if hidden is None:\n",
        "            h, c = self._init_hidden(batch_size, device)\n",
        "        else:\n",
        "            h, c = hidden\n",
        "\n",
        "        outputs = []\n",
        "        for t in range(seq_len):\n",
        "            xt = x[:, t, :]\n",
        "\n",
        "            it = torch.sigmoid(self.Wxi(xt) + self.Whi(h[-1]) + self.Wci(c))\n",
        "\n",
        "            ft = torch.sigmoid(self.Wxf(xt) + self.Whf(h[-1]) + self.Wcf(c))\n",
        "\n",
        "            ot = torch.sigmoid(self.Wxo(xt) + self.Who(h[-1]) + self.Wco(c))\n",
        "\n",
        "            gt = torch.tanh(self.Wxg(xt) + self.Whg(h[-1]))\n",
        "\n",
        "            c = ft * c + it * gt\n",
        "\n",
        "            h = ot * torch.tanh(c)\n",
        "\n",
        "            outputs.append(h)\n",
        "\n",
        "        return torch.stack(outputs, dim=1), (h, c)\n",
        "\n",
        "class WorkingMemoryLSTM(LSTMBase):\n",
        "    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.1):\n",
        "        super().__init__(input_size, hidden_size, num_layers, dropout)\n",
        "\n",
        "        self.Wxi = nn.Linear(input_size, hidden_size)\n",
        "        self.Whi = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Wci = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "        self.Wxf = nn.Linear(input_size, hidden_size)\n",
        "        self.Whf = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Wcf = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "        self.Wxo = nn.Linear(input_size, hidden_size)\n",
        "        self.Who = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Wco = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "        self.Wxg = nn.Linear(input_size, hidden_size)\n",
        "        self.Whg = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "        device = x.device\n",
        "\n",
        "        if hidden is None:\n",
        "            h, c = self._init_hidden(batch_size, device)\n",
        "        else:\n",
        "            h, c = hidden\n",
        "\n",
        "        outputs = []\n",
        "        for t in range(seq_len):\n",
        "            xt = x[:, t, :]\n",
        "\n",
        "            it = torch.sigmoid(self.Wxi(xt) + self.Whi(h[-1]) + torch.tanh(self.Wci(c)))\n",
        "\n",
        "            ft = torch.sigmoid(self.Wxf(xt) + self.Whf(h[-1]) + torch.tanh(self.Wcf(c)))\n",
        "\n",
        "            ot = torch.sigmoid(self.Wxo(xt) + self.Who(h[-1]) + torch.tanh(self.Wco(c)))\n",
        "\n",
        "            gt = torch.tanh(self.Wxg(xt) + self.Whg(h[-1]))\n",
        "\n",
        "            c = ft * c + it * gt\n",
        "\n",
        "            h = ot * torch.tanh(c)\n",
        "\n",
        "            outputs.append(h)\n",
        "\n",
        "        return torch.stack(outputs, dim=1), (h, c)\n",
        "\n",
        "class DarijaTranslator(nn.Module):\n",
        "    def __init__(self, source_vocab_size, target_vocab_size, hidden_size, lstm_type='vanilla'):\n",
        "        super().__init__()\n",
        "\n",
        "        # Embeddings\n",
        "        self.source_embedding = nn.Embedding(source_vocab_size, hidden_size)\n",
        "        self.target_embedding = nn.Embedding(target_vocab_size, hidden_size)\n",
        "\n",
        "        # Choose LSTM type\n",
        "        if lstm_type == 'vanilla':\n",
        "            self.encoder = VanillaLSTM(hidden_size, hidden_size)\n",
        "            self.decoder = VanillaLSTM(hidden_size, hidden_size)\n",
        "        elif lstm_type == 'peephole':\n",
        "            self.encoder = PeepholeLSTM(hidden_size, hidden_size)\n",
        "            self.decoder = PeepholeLSTM(hidden_size, hidden_size)\n",
        "        elif lstm_type == 'working_memory':\n",
        "            self.encoder = WorkingMemoryLSTM(hidden_size, hidden_size)\n",
        "            self.decoder = WorkingMemoryLSTM(hidden_size, hidden_size)\n",
        "\n",
        "        self.output_layer = nn.Linear(hidden_size, target_vocab_size)\n",
        "\n",
        "    def forward(self, source, target):\n",
        "        source_embedded = self.source_embedding(source)\n",
        "        target_embedded = self.target_embedding(target)\n",
        "\n",
        "        encoder_outputs, (encoder_hidden, encoder_cell) = self.encoder(source_embedded)\n",
        "\n",
        "        decoder_outputs, _ = self.decoder(target_embedded, hidden=(encoder_hidden, encoder_cell))\n",
        "\n",
        "        output = self.output_layer(decoder_outputs)\n",
        "\n",
        "        return output\n",
        "\n",
        "def prepare_dataset():\n",
        "    dataset = load_dataset(\"imomayiz/darija-english\", 'sentences')\n",
        "\n",
        "    dataset.set_format(type='pandas', output_all_columns=True)\n",
        "    dataset = dataset['sentences'][:]\n",
        "    df = dataset.dropna()\n",
        "    df = df.rename(columns={'eng': 'english'})\n",
        "    df['english'] = df['english'].apply(preprocess_text)\n",
        "    df['darija'] = df['darija'].apply(preprocess_text)\n",
        "\n",
        "    english_sentences = df['english'].tolist()\n",
        "    darija_sentences = df['darija'].tolist()\n",
        "\n",
        "    train_english, test_english, train_darija, test_darija = train_test_split(\n",
        "        english_sentences,\n",
        "        darija_sentences,\n",
        "        test_size=0.2,\n",
        "        random_state=54\n",
        "    )\n",
        "\n",
        "    return (train_english, train_darija), (test_english, test_darija)\n",
        "\n",
        "def build_vocabulary(texts, max_size=10000):\n",
        "    import spacy\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "    all_tokens = []\n",
        "    for text in texts:\n",
        "        tokens = [token.text.lower() for token in nlp(text)]\n",
        "        all_tokens.extend(tokens)\n",
        "\n",
        "    token_counts = {}\n",
        "    for token in all_tokens:\n",
        "        token_counts[token] = token_counts.get(token, 0) + 1\n",
        "\n",
        "    sorted_tokens = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    vocab = {\n",
        "        '<pad>': 0,\n",
        "        '<unk>': 1,\n",
        "        '<sos>': 2,\n",
        "        '<eos>': 3\n",
        "    }\n",
        "\n",
        "    for token, _ in sorted_tokens:\n",
        "        if token not in vocab:\n",
        "            vocab[token] = len(vocab)\n",
        "\n",
        "    return vocab\n",
        "\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device='cuda'):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    progress_bar = tqdm(dataloader, desc=\"Training\", unit=\"batch\")\n",
        "    for source, target in progress_bar:\n",
        "        source = source.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Note: For simplicity, we're using teacher forcing\n",
        "        output = model(source, target[:, :-1])\n",
        "\n",
        "        # Reshape for loss calculation\n",
        "        loss = criterion(\n",
        "            output.contiguous().view(-1, output.size(-1)),\n",
        "            target[:, 1:].contiguous().view(-1)\n",
        "        )\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip gradients to prevent exploding gradient problem, since we're using 0 dropout or weight decay\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        progress_bar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "results = compare_lstm_variants()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LrisWaiv587",
        "outputId": "62f15f63-0d95-4e58-dda8-2ffd76c11fab"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training VANILLA LSTM ---\n",
            "Using device: cuda\n",
            "\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:17<00:00,  2.05batch/s, loss=6.85]\n",
            "Evaluating: 100%|██████████| 40/40 [00:17<00:00,  2.29batch/s, loss=5.64]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 7.0393, Validation Loss: 5.4473\n",
            "\n",
            "Epoch 2/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:15<00:00,  2.12batch/s, loss=6.23]\n",
            "Evaluating: 100%|██████████| 40/40 [00:16<00:00,  2.40batch/s, loss=5.62]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.6193, Validation Loss: 5.4075\n",
            "\n",
            "Epoch 3/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:17<00:00,  2.06batch/s, loss=6.45]\n",
            "Evaluating: 100%|██████████| 40/40 [00:16<00:00,  2.40batch/s, loss=5.61]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5901, Validation Loss: 5.4424\n",
            "\n",
            "Epoch 4/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:17<00:00,  2.07batch/s, loss=7.02]\n",
            "Evaluating: 100%|██████████| 40/40 [00:17<00:00,  2.33batch/s, loss=5.61]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5851, Validation Loss: 5.4213\n",
            "\n",
            "Epoch 5/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:17<00:00,  2.06batch/s, loss=6.51]\n",
            "Evaluating: 100%|██████████| 40/40 [00:17<00:00,  2.25batch/s, loss=5.61]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5769, Validation Loss: 5.4180\n",
            "\n",
            "Epoch 6/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:22<00:00,  1.93batch/s, loss=6.64]\n",
            "Evaluating: 100%|██████████| 40/40 [00:16<00:00,  2.40batch/s, loss=5.63]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5748, Validation Loss: 5.4417\n",
            "\n",
            "Epoch 7/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:18<00:00,  2.04batch/s, loss=6.41]\n",
            "Evaluating: 100%|██████████| 40/40 [00:16<00:00,  2.44batch/s, loss=5.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5710, Validation Loss: 5.4141\n",
            "\n",
            "Epoch 8/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:17<00:00,  2.06batch/s, loss=6.81]\n",
            "Evaluating: 100%|██████████| 40/40 [00:16<00:00,  2.38batch/s, loss=5.61]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5707, Validation Loss: 5.4282\n",
            "\n",
            "Epoch 9/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:18<00:00,  2.05batch/s, loss=6.08]\n",
            "Evaluating: 100%|██████████| 40/40 [00:16<00:00,  2.44batch/s, loss=5.61]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5651, Validation Loss: 5.4243\n",
            "\n",
            "Epoch 10/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:18<00:00,  2.04batch/s, loss=6.75]\n",
            "Evaluating: 100%|██████████| 40/40 [00:16<00:00,  2.42batch/s, loss=5.58]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5662, Validation Loss: 5.4099\n",
            "\n",
            "Epoch 11/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:18<00:00,  2.05batch/s, loss=6.92]\n",
            "Evaluating: 100%|██████████| 40/40 [00:16<00:00,  2.41batch/s, loss=5.59]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5658, Validation Loss: 5.3979\n",
            "\n",
            "Epoch 12/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:19<00:00,  2.02batch/s, loss=6.24]\n",
            "Evaluating: 100%|██████████| 40/40 [00:16<00:00,  2.39batch/s, loss=5.59]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5601, Validation Loss: 5.4022\n",
            "\n",
            "Epoch 13/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:18<00:00,  2.05batch/s, loss=7.23]\n",
            "Evaluating: 100%|██████████| 40/40 [00:16<00:00,  2.37batch/s, loss=5.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5655, Validation Loss: 5.4043\n",
            "\n",
            "Epoch 14/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:17<00:00,  2.06batch/s, loss=7.01]\n",
            "Evaluating: 100%|██████████| 40/40 [00:17<00:00,  2.32batch/s, loss=5.61]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5624, Validation Loss: 5.4341\n",
            "\n",
            "Epoch 15/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:16<00:00,  2.08batch/s, loss=6.96]\n",
            "Evaluating: 100%|██████████| 40/40 [00:16<00:00,  2.40batch/s, loss=5.62]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5593, Validation Loss: 5.4333\n",
            "\n",
            "Epoch 16/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:16<00:00,  2.08batch/s, loss=6.34]\n",
            "Evaluating: 100%|██████████| 40/40 [00:16<00:00,  2.42batch/s, loss=5.62]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5552, Validation Loss: 5.4286\n",
            "\n",
            "Epoch 17/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:17<00:00,  2.06batch/s, loss=6.78]\n",
            "Evaluating: 100%|██████████| 40/40 [00:16<00:00,  2.38batch/s, loss=5.62]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5577, Validation Loss: 5.4308\n",
            "\n",
            "Epoch 18/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:16<00:00,  2.08batch/s, loss=6.28]\n",
            "Evaluating: 100%|██████████| 40/40 [00:16<00:00,  2.43batch/s, loss=5.63]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5552, Validation Loss: 5.4329\n",
            "\n",
            "Epoch 19/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:17<00:00,  2.08batch/s, loss=6.53]\n",
            "Evaluating: 100%|██████████| 40/40 [00:16<00:00,  2.45batch/s, loss=5.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5548, Validation Loss: 5.4098\n",
            "\n",
            "Epoch 20/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:17<00:00,  2.06batch/s, loss=7.05]\n",
            "Evaluating: 100%|██████████| 40/40 [00:16<00:00,  2.48batch/s, loss=5.61]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5564, Validation Loss: 5.4236\n",
            "\n",
            "--- Training PEEPHOLE LSTM ---\n",
            "Using device: cuda\n",
            "\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:23<00:00,  1.92batch/s, loss=6.98]\n",
            "Evaluating: 100%|██████████| 40/40 [00:17<00:00,  2.35batch/s, loss=5.64]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 7.1308, Validation Loss: 5.4172\n",
            "\n",
            "Epoch 2/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:22<00:00,  1.95batch/s, loss=6.59]\n",
            "Evaluating: 100%|██████████| 40/40 [00:18<00:00,  2.19batch/s, loss=5.64]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.7325, Validation Loss: 5.4413\n",
            "\n",
            "Epoch 3/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:22<00:00,  1.94batch/s, loss=7.27]\n",
            "Evaluating: 100%|██████████| 40/40 [00:17<00:00,  2.33batch/s, loss=5.61]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.7224, Validation Loss: 5.4417\n",
            "\n",
            "Epoch 4/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:21<00:00,  1.96batch/s, loss=6.59]\n",
            "Evaluating: 100%|██████████| 40/40 [00:17<00:00,  2.32batch/s, loss=5.68]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.7277, Validation Loss: 5.4666\n",
            "\n",
            "Epoch 5/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:22<00:00,  1.94batch/s, loss=6.48]\n",
            "Evaluating: 100%|██████████| 40/40 [00:18<00:00,  2.18batch/s, loss=5.62]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.7211, Validation Loss: 5.4389\n",
            "\n",
            "Epoch 6/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:23<00:00,  1.92batch/s, loss=6.46]\n",
            "Evaluating: 100%|██████████| 40/40 [00:17<00:00,  2.31batch/s, loss=5.68]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.7235, Validation Loss: 5.4694\n",
            "\n",
            "Epoch 7/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:25<00:00,  1.88batch/s, loss=6.74]\n",
            "Evaluating: 100%|██████████| 40/40 [00:17<00:00,  2.31batch/s, loss=5.63]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.7124, Validation Loss: 5.4615\n",
            "\n",
            "Epoch 8/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:24<00:00,  1.89batch/s, loss=6.54]\n",
            "Evaluating: 100%|██████████| 40/40 [00:17<00:00,  2.24batch/s, loss=5.64]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.7169, Validation Loss: 5.4420\n",
            "\n",
            "Epoch 9/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:25<00:00,  1.87batch/s, loss=7.09]\n",
            "Evaluating: 100%|██████████| 40/40 [00:17<00:00,  2.30batch/s, loss=5.64]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.7144, Validation Loss: 5.4744\n",
            "\n",
            "Epoch 10/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:23<00:00,  1.92batch/s, loss=6.98]\n",
            "Evaluating: 100%|██████████| 40/40 [00:18<00:00,  2.12batch/s, loss=5.66]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.6888, Validation Loss: 5.4597\n",
            "\n",
            "Epoch 11/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:24<00:00,  1.88batch/s, loss=6.07]\n",
            "Evaluating: 100%|██████████| 40/40 [00:17<00:00,  2.28batch/s, loss=5.65]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.6832, Validation Loss: 5.4493\n",
            "\n",
            "Epoch 12/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:23<00:00,  1.92batch/s, loss=7.38]\n",
            "Evaluating: 100%|██████████| 40/40 [00:18<00:00,  2.16batch/s, loss=5.63]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.6714, Validation Loss: 5.4386\n",
            "\n",
            "Epoch 13/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:20<00:00,  1.98batch/s, loss=6.67]\n",
            "Evaluating: 100%|██████████| 40/40 [00:16<00:00,  2.41batch/s, loss=5.65]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.6644, Validation Loss: 5.4403\n",
            "\n",
            "Epoch 14/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:19<00:00,  2.00batch/s, loss=7.05]\n",
            "Evaluating: 100%|██████████| 40/40 [00:16<00:00,  2.39batch/s, loss=5.65]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.6598, Validation Loss: 5.4516\n",
            "\n",
            "Epoch 15/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:20<00:00,  1.98batch/s, loss=6.71]\n",
            "Evaluating: 100%|██████████| 40/40 [00:18<00:00,  2.16batch/s, loss=5.63]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.6527, Validation Loss: 5.4492\n",
            "\n",
            "Epoch 16/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:21<00:00,  1.95batch/s, loss=6.54]\n",
            "Evaluating: 100%|██████████| 40/40 [00:16<00:00,  2.37batch/s, loss=5.63]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.6483, Validation Loss: 5.4266\n",
            "\n",
            "Epoch 17/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:21<00:00,  1.96batch/s, loss=6.66]\n",
            "Evaluating: 100%|██████████| 40/40 [00:16<00:00,  2.38batch/s, loss=5.65]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.6420, Validation Loss: 5.4497\n",
            "\n",
            "Epoch 18/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:20<00:00,  2.00batch/s, loss=6.97]\n",
            "Evaluating: 100%|██████████| 40/40 [00:17<00:00,  2.25batch/s, loss=5.63]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.6402, Validation Loss: 5.4484\n",
            "\n",
            "Epoch 19/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:21<00:00,  1.96batch/s, loss=6.97]\n",
            "Evaluating: 100%|██████████| 40/40 [00:17<00:00,  2.26batch/s, loss=5.65]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.6426, Validation Loss: 5.4494\n",
            "\n",
            "Epoch 20/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:24<00:00,  1.89batch/s, loss=5.9]\n",
            "Evaluating: 100%|██████████| 40/40 [00:17<00:00,  2.28batch/s, loss=5.63]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.6349, Validation Loss: 5.4360\n",
            "\n",
            "--- Training WORKING_MEMORY LSTM ---\n",
            "Using device: cuda\n",
            "\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:22<00:00,  1.94batch/s, loss=7.3]\n",
            "Evaluating: 100%|██████████| 40/40 [00:17<00:00,  2.29batch/s, loss=5.64]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 7.0202, Validation Loss: 5.4562\n",
            "\n",
            "Epoch 2/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:23<00:00,  1.91batch/s, loss=6.84]\n",
            "Evaluating: 100%|██████████| 40/40 [00:17<00:00,  2.28batch/s, loss=5.61]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.6182, Validation Loss: 5.4299\n",
            "\n",
            "Epoch 3/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:23<00:00,  1.91batch/s, loss=6.89]\n",
            "Evaluating: 100%|██████████| 40/40 [00:17<00:00,  2.31batch/s, loss=5.64]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5904, Validation Loss: 5.4504\n",
            "\n",
            "Epoch 4/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:24<00:00,  1.89batch/s, loss=6.49]\n",
            "Evaluating: 100%|██████████| 40/40 [00:17<00:00,  2.32batch/s, loss=5.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5789, Validation Loss: 5.4205\n",
            "\n",
            "Epoch 5/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:23<00:00,  1.91batch/s, loss=6.77]\n",
            "Evaluating: 100%|██████████| 40/40 [00:18<00:00,  2.20batch/s, loss=5.61]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5763, Validation Loss: 5.4268\n",
            "\n",
            "Epoch 6/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:23<00:00,  1.91batch/s, loss=6.85]\n",
            "Evaluating: 100%|██████████| 40/40 [00:17<00:00,  2.32batch/s, loss=5.58]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5730, Validation Loss: 5.4014\n",
            "\n",
            "Epoch 7/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:22<00:00,  1.93batch/s, loss=6.5]\n",
            "Evaluating: 100%|██████████| 40/40 [00:18<00:00,  2.21batch/s, loss=5.59]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5695, Validation Loss: 5.4142\n",
            "\n",
            "Epoch 8/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:23<00:00,  1.92batch/s, loss=6.2]\n",
            "Evaluating: 100%|██████████| 40/40 [00:17<00:00,  2.33batch/s, loss=5.61]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5679, Validation Loss: 5.4196\n",
            "\n",
            "Epoch 9/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:24<00:00,  1.90batch/s, loss=6.76]\n",
            "Evaluating: 100%|██████████| 40/40 [00:17<00:00,  2.27batch/s, loss=5.62]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5660, Validation Loss: 5.4184\n",
            "\n",
            "Epoch 10/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:23<00:00,  1.92batch/s, loss=6.98]\n",
            "Evaluating: 100%|██████████| 40/40 [00:17<00:00,  2.33batch/s, loss=5.61]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5682, Validation Loss: 5.4251\n",
            "\n",
            "Epoch 11/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:22<00:00,  1.94batch/s, loss=6.63]\n",
            "Evaluating: 100%|██████████| 40/40 [00:17<00:00,  2.29batch/s, loss=5.61]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5623, Validation Loss: 5.4282\n",
            "\n",
            "Epoch 12/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:22<00:00,  1.94batch/s, loss=6.55]\n",
            "Evaluating: 100%|██████████| 40/40 [00:16<00:00,  2.37batch/s, loss=5.62]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5619, Validation Loss: 5.4361\n",
            "\n",
            "Epoch 13/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:21<00:00,  1.95batch/s, loss=6.82]\n",
            "Evaluating: 100%|██████████| 40/40 [00:17<00:00,  2.30batch/s, loss=5.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5603, Validation Loss: 5.4135\n",
            "\n",
            "Epoch 14/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:24<00:00,  1.90batch/s, loss=6.22]\n",
            "Evaluating: 100%|██████████| 40/40 [00:18<00:00,  2.19batch/s, loss=5.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5558, Validation Loss: 5.4180\n",
            "\n",
            "Epoch 15/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:23<00:00,  1.91batch/s, loss=6.38]\n",
            "Evaluating: 100%|██████████| 40/40 [00:17<00:00,  2.29batch/s, loss=5.61]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5584, Validation Loss: 5.4333\n",
            "\n",
            "Epoch 16/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:23<00:00,  1.91batch/s, loss=6.2]\n",
            "Evaluating: 100%|██████████| 40/40 [00:18<00:00,  2.21batch/s, loss=5.62]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5566, Validation Loss: 5.4367\n",
            "\n",
            "Epoch 17/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:24<00:00,  1.89batch/s, loss=6.88]\n",
            "Evaluating: 100%|██████████| 40/40 [00:17<00:00,  2.29batch/s, loss=5.62]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5596, Validation Loss: 5.4311\n",
            "\n",
            "Epoch 18/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:23<00:00,  1.91batch/s, loss=6.66]\n",
            "Evaluating: 100%|██████████| 40/40 [00:17<00:00,  2.32batch/s, loss=5.62]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5561, Validation Loss: 5.4502\n",
            "\n",
            "Epoch 19/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:24<00:00,  1.90batch/s, loss=6.33]\n",
            "Evaluating: 100%|██████████| 40/40 [00:17<00:00,  2.31batch/s, loss=5.58]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5549, Validation Loss: 5.4070\n",
            "\n",
            "Epoch 20/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 160/160 [01:25<00:00,  1.87batch/s, loss=6.3]\n",
            "Evaluating: 100%|██████████| 40/40 [00:17<00:00,  2.33batch/s, loss=5.62]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 6.5516, Validation Loss: 5.4318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Huge loss, too lost in code to figure out if I'm not defining the pipeline well, or if this is a case of insufficient data, or a model that is too simple (or a mix of some of these factors)."
      ],
      "metadata": {
        "id": "_MDGEEQr3Md_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "However we test the models with a random init using 0s and the normal distribution, as we're already using Xavier's"
      ],
      "metadata": {
        "id": "dp-enuUMGhOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(model, sentence, source_vocab, target_vocab, device):\n",
        "    model.eval()\n",
        "\n",
        "    sentence = preprocess_text(sentence)\n",
        "\n",
        "\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "    source_tokens = [source_vocab['<sos>']] + \\\n",
        "                    [source_vocab.get(token.text.lower(), source_vocab['<unk>'])\n",
        "                     for token in nlp(sentence)] + \\\n",
        "                    [source_vocab['<eos>']]\n",
        "    source_tensor = torch.tensor(source_tokens).unsqueeze(0).to(device)  # Add batch dimension\n",
        "\n",
        "\n",
        "    with torch.no_grad():  # No need to track gradients during inference\n",
        "        encoder_outputs, (encoder_hidden, encoder_cell) = model.encoder(model.source_embedding(source_tensor))\n",
        "\n",
        "        decoder_input = torch.tensor([[target_vocab['<sos>']]]).to(device)\n",
        "\n",
        "        translated_tokens = []\n",
        "\n",
        "        for _ in range(50):\n",
        "            decoder_output, (decoder_hidden, decoder_cell) = model.decoder(model.target_embedding(decoder_input), (encoder_hidden, encoder_cell))\n",
        "\n",
        "            predicted_token_index = decoder_output.argmax(dim=-1).item()\n",
        "\n",
        "            if predicted_token_index == target_vocab['<eos>']:\n",
        "                break\n",
        "\n",
        "            translated_tokens.append(predicted_token_index)\n",
        "\n",
        "            decoder_input = torch.tensor([[predicted_token_index]]).to(device)\n",
        "            encoder_hidden, encoder_cell = decoder_hidden, decoder_cell\n",
        "\n",
        "    translated_sentence = \" \".join([\n",
        "        word for word, index in target_vocab.items()\n",
        "        if index in translated_tokens\n",
        "    ])\n",
        "\n",
        "    return translated_sentence\n",
        "\n",
        "example_sentence = \"This is a test sentence.\"\n",
        "lstm_type = \"peephole\"\n",
        "model = results[lstm_type]['model']\n",
        "source_vocab = build_vocabulary(prepare_dataset()[0][0])\n",
        "target_vocab = build_vocabulary(prepare_dataset()[0][1])\n",
        "translated_sentence = translate_sentence(model, example_sentence, source_vocab, target_vocab, device='cuda')\n",
        "print(f\"Original sentence: {example_sentence}\")\n",
        "print(f\"Translated sentence: {translated_sentence}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "579EF_BpRdvM",
        "outputId": "425805a2-3fbf-4414-8d5b-b815b83e2a77"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original sentence: This is a test sentence.\n",
            "Translated sentence: wach ana rah daba\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxItDccX21Ji",
        "outputId": "763a454c-18f2-4e81-8bea-ee45db16bb0c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'vanilla': {'model': DarijaTranslator(\n",
              "    (source_embedding): Embedding(4944, 256)\n",
              "    (target_embedding): Embedding(12970, 256)\n",
              "    (encoder): VanillaLSTM(\n",
              "      (Wxi): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Whi): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Wxf): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Whf): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Wxo): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Who): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Wxg): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Whg): Linear(in_features=256, out_features=256, bias=True)\n",
              "    )\n",
              "    (decoder): VanillaLSTM(\n",
              "      (Wxi): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Whi): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Wxf): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Whf): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Wxo): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Who): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Wxg): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Whg): Linear(in_features=256, out_features=256, bias=True)\n",
              "    )\n",
              "    (output_layer): Linear(in_features=256, out_features=12970, bias=True)\n",
              "  ),\n",
              "  'train_losses': [7.039285764098167,\n",
              "   6.619337540864945,\n",
              "   6.59014644920826,\n",
              "   6.585076326131821,\n",
              "   6.5768598288297655,\n",
              "   6.574825060367584,\n",
              "   6.571013167500496,\n",
              "   6.570686137676239,\n",
              "   6.565088739991188,\n",
              "   6.566190445423127,\n",
              "   6.565823155641556,\n",
              "   6.560050824284554,\n",
              "   6.5655062913894655,\n",
              "   6.562413585186005,\n",
              "   6.559321895241737,\n",
              "   6.555182874202728,\n",
              "   6.557653367519379,\n",
              "   6.555237379670143,\n",
              "   6.554797130823135,\n",
              "   6.556435161828995],\n",
              "  'val_losses': [5.447261261940002,\n",
              "   5.407461023330688,\n",
              "   5.442393660545349,\n",
              "   5.421315264701843,\n",
              "   5.418038499355316,\n",
              "   5.441746711730957,\n",
              "   5.414054477214814,\n",
              "   5.428237986564636,\n",
              "   5.424303483963013,\n",
              "   5.409911978244781,\n",
              "   5.397895383834839,\n",
              "   5.4022370219230655,\n",
              "   5.40427531003952,\n",
              "   5.434142446517944,\n",
              "   5.433291745185852,\n",
              "   5.428567028045654,\n",
              "   5.430806815624237,\n",
              "   5.432904589176178,\n",
              "   5.409813106060028,\n",
              "   5.423616886138916]},\n",
              " 'peephole': {'model': DarijaTranslator(\n",
              "    (source_embedding): Embedding(4944, 256)\n",
              "    (target_embedding): Embedding(12970, 256)\n",
              "    (encoder): PeepholeLSTM(\n",
              "      (Wxi): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Whi): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Wci): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Wxf): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Whf): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Wcf): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Wxo): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Who): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Wco): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Wxg): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Whg): Linear(in_features=256, out_features=256, bias=True)\n",
              "    )\n",
              "    (decoder): PeepholeLSTM(\n",
              "      (Wxi): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Whi): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Wci): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Wxf): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Whf): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Wcf): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Wxo): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Who): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Wco): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Wxg): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Whg): Linear(in_features=256, out_features=256, bias=True)\n",
              "    )\n",
              "    (output_layer): Linear(in_features=256, out_features=12970, bias=True)\n",
              "  ),\n",
              "  'train_losses': [7.130772805213928,\n",
              "   6.732534018158913,\n",
              "   6.722438636422157,\n",
              "   6.727677896618843,\n",
              "   6.721133822202683,\n",
              "   6.723493972420693,\n",
              "   6.712368541955948,\n",
              "   6.716930368542672,\n",
              "   6.714418408274651,\n",
              "   6.688787135481834,\n",
              "   6.683157587051392,\n",
              "   6.67135466337204,\n",
              "   6.664403182268143,\n",
              "   6.659784859418869,\n",
              "   6.652665501832962,\n",
              "   6.648303920030594,\n",
              "   6.642018818855286,\n",
              "   6.6401606649160385,\n",
              "   6.64263878762722,\n",
              "   6.6349269419908525],\n",
              "  'val_losses': [5.41715292930603,\n",
              "   5.441256415843964,\n",
              "   5.441655361652375,\n",
              "   5.466581964492798,\n",
              "   5.4389389753341675,\n",
              "   5.46935533285141,\n",
              "   5.461545622348785,\n",
              "   5.442043960094452,\n",
              "   5.474407839775085,\n",
              "   5.459665560722351,\n",
              "   5.4493108034133915,\n",
              "   5.438579690456391,\n",
              "   5.440282094478607,\n",
              "   5.451625847816468,\n",
              "   5.449158453941346,\n",
              "   5.426643455028534,\n",
              "   5.449675977230072,\n",
              "   5.448399782180786,\n",
              "   5.449437880516053,\n",
              "   5.435976994037628]},\n",
              " 'working_memory': {'model': DarijaTranslator(\n",
              "    (source_embedding): Embedding(4944, 256)\n",
              "    (target_embedding): Embedding(12970, 256)\n",
              "    (encoder): WorkingMemoryLSTM(\n",
              "      (Wxi): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Whi): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Wci): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Wxf): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Whf): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Wcf): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Wxo): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Who): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Wco): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Wxg): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Whg): Linear(in_features=256, out_features=256, bias=True)\n",
              "    )\n",
              "    (decoder): WorkingMemoryLSTM(\n",
              "      (Wxi): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Whi): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Wci): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Wxf): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Whf): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Wcf): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Wxo): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Who): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Wco): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Wxg): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (Whg): Linear(in_features=256, out_features=256, bias=True)\n",
              "    )\n",
              "    (output_layer): Linear(in_features=256, out_features=12970, bias=True)\n",
              "  ),\n",
              "  'train_losses': [7.020206961035728,\n",
              "   6.618222638964653,\n",
              "   6.590434825420379,\n",
              "   6.57890951037407,\n",
              "   6.576300179958343,\n",
              "   6.572982677817345,\n",
              "   6.569539213180542,\n",
              "   6.5678809642791744,\n",
              "   6.566035580635071,\n",
              "   6.568242299556732,\n",
              "   6.562331867218018,\n",
              "   6.561864227056503,\n",
              "   6.560331267118454,\n",
              "   6.555772802233696,\n",
              "   6.558438405394554,\n",
              "   6.55664598941803,\n",
              "   6.559598079323768,\n",
              "   6.556053712964058,\n",
              "   6.554936370253563,\n",
              "   6.551635274291039],\n",
              "  'val_losses': [5.4561715722084045,\n",
              "   5.429903674125671,\n",
              "   5.450371837615966,\n",
              "   5.420517003536224,\n",
              "   5.426811265945434,\n",
              "   5.401425397396087,\n",
              "   5.414186358451843,\n",
              "   5.419600868225098,\n",
              "   5.418390309810638,\n",
              "   5.4251330375671385,\n",
              "   5.428205037117005,\n",
              "   5.436116099357605,\n",
              "   5.413539302349091,\n",
              "   5.417966496944428,\n",
              "   5.433288824558258,\n",
              "   5.436747050285339,\n",
              "   5.431145179271698,\n",
              "   5.450243067741394,\n",
              "   5.4070117354393,\n",
              "   5.4318110823631285]}}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_sentence = \"We didn't do well in this project\"\n",
        "for lstm_type in ['vanilla', 'peephole', 'working_memory']:\n",
        "    translated_sentence = translate_sentence(model, example_sentence, source_vocab, target_vocab, device='cuda')\n",
        "    print(f\"Translated sentence with {lstm_type}: {translated_sentence}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC-zPRCSSZEg",
        "outputId": "e2407a4e-56dd-40f9-8c39-e78189014a58"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated sentence with vanilla: . wach ana rah daba\n",
            "Translated sentence with peephole: . wach ana rah daba\n",
            "Translated sentence with working_memory: . wach ana rah daba\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_sentence = \"I was lost and couldn't find the shop.\"\n",
        "for lstm_type in ['vanilla', 'peephole', 'working_memory']:\n",
        "    translated_sentence = translate_sentence(model, example_sentence, source_vocab, target_vocab, device='cuda')\n",
        "    print(f\"Translated sentence with {lstm_type}: {translated_sentence}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uV6eu-1YS0VV",
        "outputId": "3ba61d36-d7c8-4072-9f4b-479c8e8b1ff6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated sentence with vanilla: . wach ana rah daba\n",
            "Translated sentence with peephole: . wach ana rah daba\n",
            "Translated sentence with working_memory: . wach ana rah daba\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_sentence = \"I am sure.\"\n",
        "for lstm_type in ['vanilla', 'peephole', 'working_memory']:\n",
        "    translated_sentence = translate_sentence(model, example_sentence, source_vocab, target_vocab, device='cuda')\n",
        "    print(f\"Translated sentence with {lstm_type}: {translated_sentence}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3gTsVdaTQ3U",
        "outputId": "cb43a179-260b-4598-f85a-5dfa11c48713"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated sentence with vanilla: . wach ana rah daba dyalk ou\n",
            "Translated sentence with peephole: . wach ana rah daba dyalk ou\n",
            "Translated sentence with working_memory: . wach ana rah daba dyalk ou\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_sentence = \"hi\"\n",
        "for lstm_type in ['vanilla', 'peephole', 'working_memory']:\n",
        "    translated_sentence = translate_sentence(model, example_sentence, source_vocab, target_vocab, device='cuda')\n",
        "    print(f\"Translated sentence with {lstm_type}: {translated_sentence}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "innEek-iTaa6",
        "outputId": "7fc3f6d0-2bed-4280-b32c-f7fd2ddee3cf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated sentence with vanilla: wach ana rah daba dyalk ou a liyya\n",
            "Translated sentence with peephole: wach ana rah daba dyalk ou a liyya\n",
            "Translated sentence with working_memory: wach ana rah daba dyalk ou a liyya\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Absolutely horrendous, it brings to mind n-gram models."
      ],
      "metadata": {
        "id": "mYiY_sIqTksK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing more cells isn't an option since I ran out of time."
      ],
      "metadata": {
        "id": "5cDd3qyyTyF7"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ab9123f42c08423aa16d9906fe694a1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8110cac858c9446288db05bddccd4c78",
              "IPY_MODEL_97784268e3d04e07bb83bed9e658d882",
              "IPY_MODEL_2a81df29195b410583953112666ab28f"
            ],
            "layout": "IPY_MODEL_d0dbf2fcfb454731ab0fa1683a5b792c"
          }
        },
        "8110cac858c9446288db05bddccd4c78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a928ea2b8e740a8805bbc2134169c54",
            "placeholder": "​",
            "style": "IPY_MODEL_84ef4704ffc24560b942ba727b836eff",
            "value": "README.md: 100%"
          }
        },
        "97784268e3d04e07bb83bed9e658d882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9a50fa2a35349e2b70ddf3799317972",
            "max": 348,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8e564127968468898af3d13238db249",
            "value": 348
          }
        },
        "2a81df29195b410583953112666ab28f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_939626febc744970b9d14e1b9df0903e",
            "placeholder": "​",
            "style": "IPY_MODEL_d055436f79d04720bd03c0d53d50246a",
            "value": " 348/348 [00:00&lt;00:00, 22.7kB/s]"
          }
        },
        "d0dbf2fcfb454731ab0fa1683a5b792c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a928ea2b8e740a8805bbc2134169c54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84ef4704ffc24560b942ba727b836eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9a50fa2a35349e2b70ddf3799317972": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8e564127968468898af3d13238db249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "939626febc744970b9d14e1b9df0903e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d055436f79d04720bd03c0d53d50246a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3de1ce76fde44c61b2b16a0d1ddbb7c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7fbeb1ed7a9e4a22bbe26255339b1473",
              "IPY_MODEL_8759087d21a94d6496bdbbff733819a4",
              "IPY_MODEL_0bf78e0ad0be466885c93870a052df77"
            ],
            "layout": "IPY_MODEL_744b99a8fe0c496d862a851e5826bf95"
          }
        },
        "7fbeb1ed7a9e4a22bbe26255339b1473": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfd25d670baa4befbe6f83b5c512d7a7",
            "placeholder": "​",
            "style": "IPY_MODEL_47a7c33970ab496ca5d76e9851249cf4",
            "value": "sentences.csv: 100%"
          }
        },
        "8759087d21a94d6496bdbbff733819a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_347c82fe29c84173a113caf760989432",
            "max": 6337107,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a1ee67a1223412984d20073b075f124",
            "value": 6337107
          }
        },
        "0bf78e0ad0be466885c93870a052df77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01d59d717f404641a0662b8806d7fff3",
            "placeholder": "​",
            "style": "IPY_MODEL_6fc67b7b97364f77af571f1ce5cec01e",
            "value": " 6.34M/6.34M [00:03&lt;00:00, 1.83MB/s]"
          }
        },
        "744b99a8fe0c496d862a851e5826bf95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfd25d670baa4befbe6f83b5c512d7a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47a7c33970ab496ca5d76e9851249cf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "347c82fe29c84173a113caf760989432": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a1ee67a1223412984d20073b075f124": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "01d59d717f404641a0662b8806d7fff3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fc67b7b97364f77af571f1ce5cec01e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca1fdf989c5c45f98b06ff2ba512c2ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed1644d1dd044cf582f5611cac17aa48",
              "IPY_MODEL_6226f5db394742d48a617c44bcf939a9",
              "IPY_MODEL_8178fe7f673041d7a343a271b4560a31"
            ],
            "layout": "IPY_MODEL_6579af1796624f18ba21f7d09669b78b"
          }
        },
        "ed1644d1dd044cf582f5611cac17aa48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a69091abe2ed42f084380bdf45433efe",
            "placeholder": "​",
            "style": "IPY_MODEL_ec67655aecca445ab72d649d17521145",
            "value": "Generating sentences split: "
          }
        },
        "6226f5db394742d48a617c44bcf939a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_023a957f7f6345b5a63e803581dc2739",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f691fb675bde4705b7a99f52af33f502",
            "value": 1
          }
        },
        "8178fe7f673041d7a343a271b4560a31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3fb0ea703444c7684c47c25ee3be5a2",
            "placeholder": "​",
            "style": "IPY_MODEL_637f8e869ed64106af6bfaeb8f93d8c7",
            "value": " 87785/0 [00:00&lt;00:00, 268361.78 examples/s]"
          }
        },
        "6579af1796624f18ba21f7d09669b78b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a69091abe2ed42f084380bdf45433efe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec67655aecca445ab72d649d17521145": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "023a957f7f6345b5a63e803581dc2739": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f691fb675bde4705b7a99f52af33f502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3fb0ea703444c7684c47c25ee3be5a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "637f8e869ed64106af6bfaeb8f93d8c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}